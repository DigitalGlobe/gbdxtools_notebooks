{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenStreetMap as a Training Dataset\n",
    "\n",
    "In this notebook we will access and explore OSM data around Austin, TX.  OSM categorizes it's data according to the Nominatim taxonomy.  This makes for an interesting source of training data to feed to models.  Among others, the terrapattern project has used this to good effect against a ResNet-34 neural net.\n",
    "\n",
    "First let's do a little bit of setup, and establish an area of interest to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gbdxtools import Interface, TmsImage\n",
    "MAPS_API_KEY = \"pk.eyJ1IjoiZGlnaXRhbGdsb2JlIiwiYSI6ImNqMXkyZXZsODAwYWszMmsyM3lvZHBzMWsifQ.EYqlvq6QWczWsvrEDDTf7g\"\n",
    "from shapely.geometry import box, shape, mapping\n",
    "from shapely import ops\n",
    "import proj\n",
    "from rtree.index import Index as SpatialIndex\n",
    "\n",
    "gbdx = Interface()\n",
    "aoi = box(-97.803125,30.230669,-97.667427,30.306355) # Austin, TX\n",
    "boundary = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also setup a TmsImage instance to use later for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tms = TmsImage(zoom=18)\n",
    "\n",
    "[aoi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 67106304, 67108864)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll query VectorServices for OSM data in the region of interest.  We're going to ask for up to a million records back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64665 features found in search area\n"
     ]
    }
   ],
   "source": [
    "osm_data = gbdx.vectors.query(aoi.wkt, query=\"item_type:* AND ingest_source:OSM AND geom_type:Polygon\", \n",
    "                              index=\"vector-osm-*\", count=1E6)\n",
    "print(\"{} features found in search area\".format(len(osm_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the original OpenStreetMap attributes of one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_osm_changeset': u'35577335',\n",
       " u'_osm_copyright': u'\\xa9 OpenStreetMap contributors',\n",
       " u'_osm_license': u'http://www.opendatacommons.org/licenses/odbl',\n",
       " u'_osm_user_id': u'3369502',\n",
       " u'_osm_user_name': u'patisilva_atxbuildings',\n",
       " u'_osm_version': u'1',\n",
       " u'building': u'yes',\n",
       " u'height': u'5.9'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_data[0][\"properties\"][\"attributes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this feature is a building and that, in general, feature attributes are stored in non-underscored fields of the attributes structure.  Let's reject the `height` key and a few other types of keys we know about.  We'll explore further using Python's Counter class.  Note that the reject condition (and additional pieces were developed by iteratively examining the results observed in the counter class).  There's no guarantee we've gotten it perfectly right and the experience around this is quite bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'building', 62401),\n",
       " (u'bench', 111),\n",
       " (u'area', 55),\n",
       " (u'access', 35),\n",
       " (u'lit', 31),\n",
       " (u'wheelchair', 29),\n",
       " (u'oneway', 12),\n",
       " (u'capacity', 7),\n",
       " (u'climbing', 6),\n",
       " (u'supervised', 5),\n",
       " (u'garage', 4),\n",
       " (u'toilets', 3),\n",
       " (u'shop', 2),\n",
       " (u'fee', 2),\n",
       " (u'fuel', 2),\n",
       " (u'historic', 2),\n",
       " (u'atm', 2),\n",
       " (u'takeaway', 2),\n",
       " (u'drive_through', 1),\n",
       " (u'bicycle', 1),\n",
       " (u'health_specialty', 1),\n",
       " (u'heritage', 1),\n",
       " (u'covered', 1),\n",
       " (u'emergency', 1),\n",
       " (u'foot', 1),\n",
       " (u'outdoor_seating', 1),\n",
       " (u'construction', 1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "rejected_keys = set([\"height\", \"import\"])\n",
    "reject_condition = lambda t: (t.startswith(\"_\") \n",
    "                              or t.startswith(\"addr:\")\n",
    "                              or t.startswith(\"coa:\")\n",
    "                              or t.startswith(\"source\")\n",
    "                              or t.startswith(\"tiger:\")\n",
    "                              or t in rejected_keys)\n",
    "\n",
    "osm_types = Counter([t.split(\":\")[0] for rec in osm_data for t,v in rec[\"properties\"][\"attributes\"].iteritems() \n",
    "                     if not reject_condition(t) and v == \"yes\"])\n",
    "osm_types.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of feature types here that could be useful in characterizing an area.  It is rather unfortunate that most are generically buildings rather than something more specific, but let's pretend and move on.\n",
    "\n",
    "To view this dataset as training data, we want to create two helper functions.  One that takes a collection of features and converts them to a consistent feature vector (based on the categories above) and a second that quickly looks up features in a particular geographic region.\n",
    "\n",
    "For the first function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup a categorical basis with consistent order\n",
    "basis = [k for k,v in osm_types.most_common(100)]\n",
    "\n",
    "# use the identical counter technique and produce a vector where each element is 1 or 0\n",
    "# depending on whether a feature type exists in the feature set.\n",
    "def basis_vector(features):\n",
    "    stats = Counter([t.split(\":\")[0] for rec in features for t,v in rec[\"properties\"][\"attributes\"].iteritems() \n",
    "                     if not reject_condition(t) and v == \"yes\"])\n",
    "    return [int(k in stats) for k in basis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second function we need to create a client-side spatial index to look up features because querying VectorServices during training will be too slow.  We'll call the first helper function within the second so that it can be used directly by a training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osm_index = SpatialIndex()\n",
    "for idx, rec in enumerate(osm_data):\n",
    "    osm_index.add(idx, shape(rec[\"geometry\"]).bounds, rec)\n",
    "\n",
    "def lookup_basis_vector(g):\n",
    "    features = [rec.object for rec in osm_index.intersection(g.bounds, objects=True)]\n",
    "    return basis_vector(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8715ca751d0b437c9e4c0bebc8ce4fb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: lookup from model\n",
    "row_chunk = 301\n",
    "col_chunk = 301\n",
    "\n",
    "# NOTE: Dropping far boundary, should fix\n",
    "row_lims = xrange(row_chunk, tms_region.shape[1], row_chunk)\n",
    "col_lims = xrange(col_chunk, tms_region.shape[2], col_chunk)\n",
    "\n",
    "training_data = []\n",
    "for maxy, maxx in tqdm(cartesian_prod(row_lims, col_lims),\n",
    "                       total=len(row_lims)*len(col_lims)):\n",
    "    region = tms_region[:, (maxy-row_chunk):maxy, (maxx-col_chunk):maxx]\n",
    "    training_data.append((region, lookup_basis_vector(region)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
